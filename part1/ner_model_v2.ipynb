{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c13604",
   "metadata": {},
   "source": [
    "# Part 1 - NER Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d547de",
   "metadata": {},
   "source": [
    "### Download libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd06c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "INPUT_FILE_PATH = 'teachers_db_practice.parquet'\n",
    "PREDS_FILE_PATH = 'ner_predictions_v2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85e78ce",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129a06d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_csv = pd.read_csv('teachers_db_practice.csv')\n",
    "df_parquet = pd.read_parquet(INPUT_FILE_PATH, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19b6b505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<p>  has worked as a designer for the last decade in roles spanning a '\n",
      " 'variety of disciplines from graphics to product to interiors. In 2017, , '\n",
      " 'became studio director at Vidivixi, a furniture and interiors design '\n",
      " 'practice based in Mexico City. After leaving in 2023 and relocating to Spain '\n",
      " 'he opened a new design studio with a focus on bespoke, contemporary '\n",
      " 'design-led furniture.\\xa0</p><h4>Corporate Experience</h4><p>• Studio '\n",
      " 'Director, A&amp;M Studio, Spain, 2023 – Present</p><p>• Studio Director, '\n",
      " 'Vidivixi, Mexico, 2017 – 2023</p><p>• Associate, Becquerel Capital, Mexico, '\n",
      " '2014 – 2017</p><p>• Design Partner, The Hub, Hong Kong, 2013 – '\n",
      " '2014</p><h4>Academic Background</h4><p>• Bachelor in Graphic Design, '\n",
      " 'Camberwell College of Arts UAL, U.K., 2013</p>')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(df_parquet.iloc[0, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f260e1",
   "metadata": {},
   "source": [
    "### Import libraries and model from huggingface: dslim/bert-base-NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d83a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelfa/Desktop/DAI-A1-INSTRUCTIONS/dai-a1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df02709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa7403",
   "metadata": {},
   "source": [
    "### Define Pipeline, Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1fc9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:1\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained('dslim/bert-base-NER')\n",
    "#model = AutoModelForTokenClassification.from_pretrained('dslim/bert-base-NER')\n",
    "ner_model = pipeline(task='ner', model='dslim/bert-base-NER', aggregation_strategy='simple', device=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088826b9",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63dcfed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import html\n",
    "\n",
    "# V2\n",
    "\n",
    "def parse_full_info(html_text):\n",
    "    # parse html\n",
    "    text = html.unescape(html_text.replace(\"\\xa0\", \" \"))\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "\n",
    "    # create lists\n",
    "    summary = \"\"\n",
    "    corporate_experience = []\n",
    "    academic_experience = []\n",
    "    academic_background = []\n",
    "\n",
    "    # all is summary unless stated\n",
    "    sections = soup.find_all([\"p\", \"h4\"])\n",
    "    current_section = \"summary\"\n",
    "\n",
    "    for tag in sections:\n",
    "        if tag.name == \"h4\":\n",
    "            title = tag.get_text(strip=True).lower()\n",
    "            if \"corporate\" in title.lower():\n",
    "                current_section = \"corporate\"\n",
    "            elif \"academic experience\" in title.lower():\n",
    "                current_section = \"academic\"\n",
    "            elif \"academic background\" in title.lower():\n",
    "                current_section = \"studies\"\n",
    "            else:\n",
    "                current_section = \"summary\"\n",
    "        elif tag.name == \"p\":\n",
    "            text_block = tag.get_text(strip=True)\n",
    "            if current_section == \"summary\":\n",
    "                summary += \" \" + text_block\n",
    "            elif current_section == \"corporate\":\n",
    "                corporate_experience.append(text_block)\n",
    "            elif current_section == \"academic\":\n",
    "                academic_experience.append(text_block)\n",
    "            elif current_section == \"studies\":\n",
    "                academic_background.append(text_block)\n",
    "\n",
    "    return {\n",
    "        'summary': summary.strip(),\n",
    "        'corporate_experience': corporate_experience,\n",
    "        'academic_experience': academic_experience,\n",
    "        'academic_background': academic_background\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d5fa42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_professor(full_info):\n",
    "    parsed = parse_full_info(full_info)\n",
    "\n",
    "    results = {\n",
    "        'corporate_experience': {'companies': [], 'locations': []},\n",
    "        'academic_experience': {'universities': [], 'degrees': [], 'locations': []},\n",
    "        'academic_background': {'universities': [], 'degrees': [], 'locations': []}\n",
    "    }\n",
    "\n",
    "    # NER on corporate experience\n",
    "    for exp in parsed['corporate_experience']:\n",
    "        ents = ner_model(exp)\n",
    "        for e in ents:\n",
    "            if e['entity_group'] == 'ORG':\n",
    "                results['corporate_experience']['companies'].append(e['word'])\n",
    "            elif e['entity_group'] == 'LOC':\n",
    "                results['corporate_experience']['locations'].append(e['word'])\n",
    "\n",
    "    # NER on academic experience\n",
    "    for aca in parsed['academic_experience']:\n",
    "        ents = ner_model(aca)\n",
    "        for e in ents:\n",
    "            if e['entity_group'] == 'ORG':\n",
    "                results['academic_experience']['universities'].append(e['word'])\n",
    "            elif e['entity_group'] == 'MISC':\n",
    "                results['academic_experience']['degrees'].append(e['word'])\n",
    "            elif e['entity_group'] == 'LOC':\n",
    "                results['academic_experience']['locations'].append(e['word'])\n",
    "    \n",
    "    # NER on academic background\n",
    "    for edu in parsed['academic_background']:\n",
    "        ents = ner_model(edu)\n",
    "        for e in ents:\n",
    "            if e['entity_group'] == 'ORG':\n",
    "                results['academic_background']['universities'].append(e['word'])\n",
    "            elif e['entity_group'] == 'MISC':\n",
    "                results['academic_background']['degrees'].append(e['word'])\n",
    "            elif e['entity_group'] == 'LOC':\n",
    "                results['academic_background']['locations'].append(e['word'])\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b146eeca",
   "metadata": {},
   "source": [
    "## Trying out on short dataset (df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07040ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_parquet.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6b8fd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lc/prdjgf0d6hb4tg221lphh9cc0000gn/T/ipykernel_18914/2888795161.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_copy[\"entities\"] = df_copy[\"full_info\"].apply(extract_info_from_professor)\n"
     ]
    }
   ],
   "source": [
    "df_copy[\"entities\"] = df_copy[\"full_info\"].apply(extract_info_from_professor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea915cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corporate_experience': {'companies': ['A & M Studio', 'Becquerel Capital'],\n",
       "  'locations': ['Spain',\n",
       "   'V',\n",
       "   '##idivixi',\n",
       "   'Mexico',\n",
       "   'Mexico',\n",
       "   'The Hub',\n",
       "   'Hong Kong']},\n",
       " 'academic_experience': {'universities': [], 'degrees': [], 'locations': []},\n",
       " 'academic_background': {'universities': ['Camberwell College of Arts UAL'],\n",
       "  'degrees': ['Design'],\n",
       "  'locations': ['U. K.']}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[0, 'entities']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce71df2",
   "metadata": {},
   "source": [
    "## Apply to df_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a991710",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_parquet.copy()\n",
    "df_pred['entities'] = df_parquet['full_info'].apply(extract_info_from_professor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "769780cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "need to escape, but no escapechar set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPREDS_FILE_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/DAI-A1-INSTRUCTIONS/dai-a1/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/DAI-A1-INSTRUCTIONS/dai-a1/lib/python3.10/site-packages/pandas/core/generic.py:3989\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3978\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3980\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3981\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3982\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3986\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3987\u001b[0m )\n\u001b[0;32m-> 3989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3992\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3994\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4006\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/DAI-A1-INSTRUCTIONS/dai-a1/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/Desktop/DAI-A1-INSTRUCTIONS/dai-a1/lib/python3.10/site-packages/pandas/io/formats/csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/DAI-A1-INSTRUCTIONS/dai-a1/lib/python3.10/site-packages/pandas/io/formats/csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/DAI-A1-INSTRUCTIONS/dai-a1/lib/python3.10/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/DAI-A1-INSTRUCTIONS/dai-a1/lib/python3.10/site-packages/pandas/io/formats/csvs.py:324\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[1;32m    323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[0;32m--> 324\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mpandas/_libs/writers.pyx:56\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: need to escape, but no escapechar set"
     ]
    }
   ],
   "source": [
    "df_pred.to_csv(PREDS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f17006a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_parquet(\"ner_predictions_v2.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dai-a1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
